
\iffalse

\section{Literature}
\label{sec:literature}

For private equity funds, performance evaluation under the SDF framework is currently an active research topic \citep{DLP12,FNP12,B14,B16a,B16b,KN16,ACGP18,GSW19}.
Previously, SDF performance evaluation was already applied for public stock markets by, e.g., \cite{FFJT02} and for hedge fund returns by \cite{LXZ16}.

In our literature review, we focus on the most relevant parametric and semiparametric estimation methods for private capital fund cash flows.


\subsection{Parametric approach}

\cite{ACGP18} contribute a parametric approach using Bayesian Markov Chain Monte Carlo methods to estimate latent return factors from present value ratios.
\cite{ACGP18} use fund-level data provided by Preqin to estimate a "PE return index based on historical fund cash flows."
As Data Generating Process (DGP), they assume a log-linear factor model for each fund distribution
\begin{equation}
	\label{eq:data_generating_process}
	D_T = C_t \prod_{\tau=t+1}^{T} g_{\tau}
\end{equation}
where $D_T$ is a given fund distribution and $C_t$ a contribution with $t<T$.
The return dynamics $\ln (g_t) = \ln (g_t^M) + \epsilon_t$ where $g_t^M$ is the market component of the fund return and $\epsilon_t$ its idiosyncratic part that is normal and i.i.d.
The state space dynamics of the filtering problem describe the factor model structure of $g$ as
\[
g_t^M = \alpha + r_t^{\mathrm{free}} + \beta^{\top} F_t + f_t^{\mathrm{PE}}
\]
where $\alpha$ is the average excess return, $r_t^{\mathrm{free}}$ is the risk-free rate, $F_t$ is a vector of public market (long-short) factor returns, $\beta$ the corresponding factor loadings, and $f_t^{\mathrm{PE}}$ is "an asset-class-specific latent factor with mean zero that is orthogonal to the traded factors, $F_t$."
They assume each fund holds $N$ investments $i=1,2,\dots,N$; $t_i$ notes the investment date of the first deal and $T_i$ is the corresponding exit date.
For each fund, they then postulate the following Present Value Ratio ($PVR$) to hold
\begin{equation}
	\label{eq:pvr_ang_2018}
	PVR = \ln \left(\frac{PV_D}{PV_C}\right) \cong \ln (u) \qquad \mathrm{where} \quad \ln (u) \sim N \left( - 0.5 \sigma^2, \sigma^2 \right)
\end{equation}
with present value of distributions
\[
PV_D = \sum_{i=1}^N \frac{D_{T_i}}{g_{t_1} \dots g_{T_i}}
\]
and present value of contributions
\[
PV_C = \sum_{i=1}^N \frac{C_{i}}{g_{t_1} \dots g_{T_i}} U_{t_i, T_i}
\]
where $U_{t_i, T_j}$ contains the idiosyncratic terms
\[
U_{t_i, T_j}^i = \exp \left( \epsilon_{t_i + 1} + \dots + \epsilon_{T_i} \right)
\]
Here, the approximation ($\cong$) of the PVR by $\ln (u)$ relies on a lognormal central limit theorem (CLT) obtained from the textbook of \cite{BT13}.
For this CLT to hold, they need the two \textbf{regularity conditions} that there is no dominantly (i) large or (ii) long investment as $N$ goes to infinity.
They estimate all relevant model parameters, i.e., $\alpha,\beta$ and the latent residual return time-series $f^{\mathrm{PE}}$, by a Bayesian Markov Chain Monte Carlo method that minimizes "one large error term per fund in the estimation process".
Thus \cite{ACGP18} provide the first SDF estimation method in the literature that not only estimates the public market factors but additionally an \textbf{asset-class-specific latent factor}.
Because of the high dimensionality of $f^{\mathrm{PE}}$ (i.e., a return time-series), they need to employ an estimation method like Gibbs sampling that can handle more parameters to estimate than actual data points.
Inspired by these ``latent factors", \cite{TP24} propose a machine-learning approach to estimate the error-term time series of public factor models for private capital funds.

\subsection{Semiparametric approaches}

Semiparametric approaches omit (i) parametric specifications for the idiosyncratic error term and (ii) often also formulations of the concrete Data Generating Process (DGP).

\cite{DLP12} develop the first SDF estimator tailored for typical PE fund-level cash flows.
Their goal is to estimate a linear factor model that minimizes the squared $DNCF$ of PEFs.
Generically, they solve the following minimization problem
\begin{equation}
	\theta^{\mathrm{SDF}} = 
	\arg \min_{\theta^{\mathrm{SDF}}} \sum_{i=1}^N 
	\left[ 
	\sum_{t=1}^{T_i}
	\left(
	\frac{D_{it} - C_{it}}{\Psi_{t}^{-1}}
	\right)
	\right]^2
\end{equation}
where $N$ is the number of PEF portfolios in the dataset.
$\theta^{\mathrm{SDF}}=(\alpha, \beta)$ are the coefficients of a linear factor model SDF with $\Psi_t=(\prod_{\tau=0}^t R_{\tau})^{-1}$ where $R_{\tau}$ follows a \textbf{linear return factor model}
\begin{equation}
	R_{\tau}=1+\alpha_{\tau}+\beta^{\top}F_{\tau}+\epsilon_{\tau}
\end{equation}
where the risk-free rate is the first element of the vector $F_{\tau}$.
Plugging these terms into Equation \ref{eq:dlp12_minimization} yields
\[
\left( \alpha, \beta \right) 
= 
\arg \min_{\alpha, \beta} 
\sum_{i=1}^N 
\left( 
\sum_{t=1}^{T_i}
\frac{D_{i,t} - C_{i,t}}{\prod_{\tau=0}^t (1 + \alpha_{\tau}+\beta^{\top}F_{\tau}+\epsilon_{\tau}) } 
\right)^2
\]
which constitutes a nonlinear least squares optimization problem.
However, \cite{DLP12} \textbf{interpret their approach as Generalized Method of Moments (GMM) estimator} with $N$ moment conditions and identity weighting matrix where asymptotically the number of underlying investments per portfolio $i$ tends to infinity.
In our view, this cross-sectional GMM interpretation is both unnecessarily (i) complex and (ii) unrealistic.
Especially, their GMM derivation (in the internet appendix) takes as starting point a DGP similar to Equation \ref{eq:data_generating_process} but does not show why their nontraditional GMM interpretation is favorable to traditional (and simpler) non-linear least squares as defined, e.g., by \cite{PP97}.
Instead of using individual funds, they form $N$ \textbf{vintage year portfolios} where they pool all fund cash flows from a given vintage "to lower the effect of idiosyncratic shocks," similar to \cite{FNP12}.
To obtain standard errors for their coefficient estimates, the authors rely on cross-sectional bootstrapping \textbf{instead of providing} an asymptotic inference formula.
Empirically, the paper draws on the problematic Thomson Venture Economics (TVE) fund-level dataset that exhibits some now well-known data errors as discussed by \cite{HJK14}.
For VC, they estimate a one-factor model with a market beta factor of 2.73 and an annualized negative alpha of -12.3\%. For BO, one-factor model coefficients are 1.31 for the market factor, and the annualized alpha is again negative with -4.8\%.
These highly negative alpha terms can be at least partially attributed to the aforementioned data errors in the TVE dataset.
However, surprisingly from a methodological viewpoint, both alpha terms must be considered insignificantly different from zero due to high bootstrap standard errors.
In summary, we still consider the \cite{DLP12} paper a seminal contribution to the PE literature as it proposes the first semiparametric SDF estimator for typical PEF (fund-level) datasets.  


\cite{KN16} introduce the Generalized Public Market Equivalent (GPME) framework, which is a new SDF-based performance evaluation methodology for PE fund-level cash flows.
The general idea is to first estimate a given SDF just on a public market dataset and then, in the second step, evaluate PEF cash flows by a traditional NPV approach
\[
GPME = \sum_t \Psi_t^{\mathrm{public}} CF_t^{\mathrm{PEF}}
\]
where $\Psi_t^{\mathrm{public}}$ is a generic SDF estimated on public data and $CF_t^{\mathrm{PEF}}$ are all cash flows of a (liquidated) PEF.
Here, GPME is simply our DNCF from Equation \ref{eq:net_present_value}.
However, their paper also offers one new and important methodical insight for SDF estimation using PE cash flow data.
They are the first to realize that for asymptotic statistical inference, a \textbf{spatial heteroskedasticity and autocorrelation consistent (SHAC)}\footnote{A SHAC estimator will be later applied and defined by Equation \ref{eq:hac}.} covariance matrix estimator that incorporates the economic distance between PE fund pairs proves very useful.
To estimate their exponentially affine SDF, they apply a time-series Generalized Method of Moments (GMM) approach where they, for simplicity, assume an identity weighting matrix.
This corresponds to a very similar minimization problem as the one from Equation \ref{eq:dlp12_minimization}, which is used by \cite{DLP12}. 
They form public replication portfolios that mimic PEF contributions and distributions patterns and use these synthetic cash flows for SDF estimation. 
Interestingly, they claim that an exponentially affine SDF is especially suited for "irregularly spaced, skewed, and endogenously timed payoffs" of VC investments.
Moreover, they state: "With irregularly spaced and skewed VC cash flow data, \textbf{linear factor models are not readily applicable} without strong distributional assumptions."
Empirically, the authors calculate their GPME metric for VC funds from the Preqin fund-level dataset and start-ups from Sand Hill Econometrics' deal-level data.
Unfortunately, they relinquish to also test a linear factor model as an alternative to their exponential affine SDF to underpin their strong allegation about the correct SDF choice.
It is also not clear why they cannot use a public SDF that has been estimated on a traditional public stock return (not cash flow) dataset (comparable to the \cite{GSW19} approach, which is discussed in the next paragraph).
From this perspective, their non-traditional GMM estimator and the construction of the public benchmark portfolio cash flows seem unnecessarily complicated and artificial.

In a more recent paper \cite{KN22} extend their GPME methodology to obtain risk-adjusted benchmarks for single PE funds.
\cite{NSS22} adapt the GPME method to estimate their so-called Credit Market Equivalent which relies on an SDF that prices the bonds issued by buyout-held companies.
Interestingly, \cite{NSS22} find that public credit market factors can better price PE cash flows than the traditional public stock market factors.
Similarly, \cite{GJ21} test the GPME approach using a CAPM SDF and a "Discount Rate News" SDF.
Although we think pricing PE cash flows instead of public market cash flows is the more natural approach (as \cite{GJ21} and \cite{NSS22} did), \cite{KN16,KN22} still mark highly significant contributions to the PE-related SDF literature.

The unpublished working paper of \cite{GSW19} evaluates PE fund-level cash flows by means of asset pricing tests for ``off-the-shelf" SDFs.
They examine SDFs that shall be presumably better aligned with typical PE investor preferences than traditional factor models like \cite{FF15}.
Specifically, they test two leading consumption-based asset pricing models: the long-run risk model of \cite{BY04} and the external habit formation model of \cite{CC99} among other simpler SDF alternatives.
Notably, in the first place, the authors take SDF parameters from the existing literature rather than estimating their own SDF coefficients.
This is comparable to the \cite{KN16} generalized PME framework, which also does not uses any PE cash flows for SDF estimation.
Their SDF can thus be considered as universal SDFs that can price all cash flows in a given economy (not just PE cash flows specifically).
Just in their additional results section \cite{GSW19} ``are trying to 'fine-tune' the off-the-shelf SDFs to reduce the benchmark pricing errors".
Empirically, they obtain unrealistically large negative risk-free rate parameters when fitting SDFs to fund cash flows from the Burgiss database.
Most interestingly, they claim to ``show that cash flow NPV-based measures of performance for long-duration investment vehicles like PE funds are biased relative to per-period abnormal return estimates."
In other words, they criticize asset pricing tests that are based on a general NPV-equal-to-zero condition (cf.\ Equation \ref{eq:basic_pricing_relation}).
Their derived bias term is non-zero if there exits any auto-correlation in the time-series of (unobserved) pricing errors $e_t = \Psi_t R_t - 1$ were $\Psi_t$ is a SDF and $R_t$ is the latent periodic PE return.
Here they assume a data generating process similar to Equation \ref{eq:data_generating_process}, which is used by \cite{ACGP18}.
\textcolor{red}{
	To better understand their ``compounding error" \textbf{small-sample bias}, it is important to mention that in small samples, we may measure a nonzero autocorrelation for some error terms even if this effect vanishes asymptotically and the true expected autocorrelation is zero.
}
So, we generally agree that asset pricing tests for PE cash flow datasets are always weaker than standard time-series asset pricing tests that could draw on the latent true return time-series of PE returns.
Moreover, their idea to \textbf{price the difference between PE cash flows and a suitable public replication strategy} instead of just PE cash flows (as a resolution of their bias issue) is picked up by the quadratic hedging strategies derived by \cite{T19}.

\fi







\iffalse

% TODO: delete
{
	\color{red}
	\paragraph{Wrong Derivation}
	In this realistic setting, the absence of observable market valuations considerably contributes to the difficulty of our pricing problem.
	However, also the existence of only pooled cash flows, instead of granular deal-by-deal cash flows, introduces issues for pricing approaches like \cite{DLP12} that discount to the fund inception date (see Equation \ref{eq:dlp12_minimization}).
	In the following, we will demonstrate why we cannot easily price pooled fund-level cash flow streams without introducing \textbf{inevitable bias terms} (even for fund inception date $\tau = \min_j t_{i,j}^{\mathrm{Inv}}$).
	Generally, all deal-level cash flows will produce the following ``bias term"
	\begin{equation}
		\label{eq:deal_level_bias}
		\mathbb{E} \left[ 
		\frac{\Psi_{t_{i,j}^{\mathrm{Inv}}}}{\Psi_{\tau}}
		\delta_{i,j}
		\left| \mathcal{F}_{\tau} \right.
		\right]
		=
		\mathrm{Cov} \left[ \frac{\Psi_{t_{i,j}^{\mathrm{Inv}}}}{\Psi_{\tau}}, \ \delta_{i,j} \right]
		\quad \forall \ \tau < t_{i,j}^{\mathrm{Inv}}
	\end{equation}
	Only for the trivial case of Equation \ref{eq:deal_pricing}, where the investment date coincides with the discounting date $\tau =  t_{i,j}^{\mathrm{Inv}}$, the covariance term necessarily equals zero.
	For the fund-level cash flows, we therefore introduce the following proposition.
	\begin{proposition}
		\label{theo:pooled_bias}
		Price of a pooled cash flow stream at fund inception: \\
		\begin{equation}
			\label{eq:price_pooled_cash_flows_wrong}
			\mathbb{E} \left[ 
			\sum_{t = \tau}^T
			\frac{\Psi_{t}}{\Psi_{\tau}}
			{CF}_{i,t}
			\left| \mathcal{F}_{\tau} \right.
			\right]
			=
			\sum_{j=1}^J
			\mathrm{Cov} \left[ \frac{\Psi_{t_{i,j}^{\mathrm{Inv}}}}{\Psi_{\tau}}, \ \delta_{i,j} \right]
			\ \forall \ i
		\end{equation}
		with fund inception date $\tau = \ \min_j \mathrm{Inv}_{i,j}$.
	\end{proposition}
	
	We can simply proof the proposition as follows.
	\begin{proof}
		We start with using Point 4 of Assumption \ref{ass:deal_level_dgp} which states that fund-level cash flows are the sum of deal-level cash flows.
		Further, we stipulate in the proposition that no deal-level cash flow occurs before $\tau$.
		Thus, the expected value of discounted fund-level cash flows needs to equal the expected value of discounted deal-level cash flows. 
		\begin{equation}
			\label{eq:price_pooled_cash_flows_proof_1_wrong}
			\mathbb{E} \left[ 
			\sum_{t = \tau}^T
			\frac{\Psi_{t}}{\Psi_{\tau}}
			{CF}_{i,t}
			\left| \mathcal{F}_{\tau} \right.
			\right]
			=
			\mathbb{E} \left[ 
			\sum_{j=1}^J
			\frac{\Psi_{t_{i,j}^{\mathrm{Inv}}}}{\Psi_{\tau}}
			\delta_{i,j}
			\left| \mathcal{F}_{\tau} \right.
			\right]
		\end{equation}
		Using Equation \ref{eq:deal_level_bias}, we can rewrite
		\begin{equation}
			\label{eq:price_pooled_cash_flows_proof_2_wrong}
			\mathbb{E} \left[ 
			\sum_{j=1}^J
			\frac{\Psi_{t_{i,j}^{\mathrm{Inv}}}}{\Psi_{\tau}}
			\delta_{i,j}
			\left| \mathcal{F}_{\tau} \right.
			\right]
			=
			\mathbb{E} \left[ 
			\sum_{j=1}^J
			\mathrm{Cov} \left[ \frac{\Psi_{t_{i,j}^{\mathrm{Inv}}}}{\Psi_{\tau}}, \ \delta_{i,j} \right]
			\left| \mathcal{F}_{\tau} \right.
			\right]
		\end{equation}
		Linearity of expectations then yields the result we want to proof.
		\begin{equation}
			\label{eq:price_pooled_cash_flows_proof_3}
			\mathbb{E} \left[ 
			\sum_{j=1}^J
			\mathrm{Cov} \left[ \frac{\Psi_{t_{i,j}^{\mathrm{Inv}}}}{\Psi_{\tau}}, \ \delta_{i,j} \right]
			\left| \mathcal{F}_{\tau} \right.
			\right]
			=
			\sum_{j=1}^J
			\mathrm{Cov} \left[ \frac{\Psi_{t_{i,j}^{\mathrm{Inv}}}}{\Psi_{\tau}}, \ \delta_{i,j} \right]
		\end{equation}
	\end{proof}
	
	
	\begin{corollary}
		\label{cor:same_investment_dates}
		If and only if all deal investment dates coincide with the fund inception date, i.e., $\mathrm{Inv}_{i,j} = \min_j \mathrm{Inv}_{i,j} \forall j$, we have
		\begin{equation}
			\label{eq:price_pooled_cash_flows_corollary}
			\mathbb{E} \left[ 
			\sum_{t = \tau}^T
			\frac{\Psi_{t}}{\Psi_{\tau}}
			{CF}_{i,t}
			\left| \mathcal{F}_{\tau} \right.
			\right]
			=
			0
		\end{equation}
		for the standard case where we do not assume independence between $\Psi$ and $\delta_{i,j}$.
	\end{corollary}
	
	The asset pricing problem for realistic private equity fund cash flows is aggravated by bridge financing, management fees and carry cash flows that further distort the deal-level cash flows.
}

\fi



\iffalse


We start with the following classical ``fair pricing" relation for $\tau = 0$
\marginpar{\scriptsize Analyze \\ the case \\ $\tau \neq 0$}
\begin{equation}
	\label{eq:basic_pricing_relation}
	\mathbb{E} \left[ 
	\epsilon_{\tau,i}
	\left| \mathcal{F}_{0} \right.
	\right] = 0
	\quad \forall \ i, \ \tau = 0
\end{equation}

% Wrong investment date in future
Now let us analyze special cases for $\tau > 0$ that could be interesting for private capital funds or other \emph{pooled} cash flow streams.
First, we assume the investment decision for a given deal is formed at the later date $\tau > 0$ and thus we have the following correct pricing relation $\mathbb{E} \left[ \epsilon_{\tau,i} \left| \mathcal{F}_{\tau} \right. \right] = 0$.
In this case, the classical fair pricing Equation \ref{eq:basic_pricing_relation} vice versa introduces the reciprocal non-zero expected pricing error term 
\marginpar{\scriptsize  Pricing with future information}
\begin{equation}
	\label{eq:wrong_date_pricing_relation}
	\mathbb{E} \left[ 
	\epsilon_{0,i}
	\left| \mathcal{F}_{0} \right.
	\right] = 
	\mathrm{Cov}_{0} \left[ \frac{\Psi_{\tau}}{1}, \epsilon_{\tau,i} \right]
	\quad \forall \ i, \ \tau > 0
\end{equation}
This means for pooled cash flow stream, consisting over several projects with distinct starting dates, and thus without a correct global $t=0$, we always introduce  non-zero expected pricing errors and no classical pricing relation holds.
Without detailed knowledge about the underlying sub-projects of given fund (i.e., deal-level cash flows), it is impossible to exactly distinguish Equations \ref{eq:future_value_pricing_relation} from \ref{eq:wrong_date_pricing_relation}.

% Compounding as solution?
Generally, we know for $\tau > 0$
\marginpar{\scriptsize How to proof that Cov is small? \\ Deal-level cash flows are discounted too much!}
\begin{equation}
	\label{eq:future_value_pricing_relation}
	\mathbb{E} \left[ 
	\epsilon_{\tau,i}
	\left| \mathcal{F}_{0} \right.
	\right] = 
	\mathrm{Cov}_0 \left[ \frac{1}{\Psi_{\tau}}, \epsilon_{0,i} \right]
	\quad \forall \ i, \ \tau > 0
\end{equation}
This means we introduce a non-zero expected pricing error term on purpose, which seems odd.

\fi




\subsection{Future and present value dates: the set $\mathcal{T}$}
\label{subsec:npv_vs_fv}

This subsection helps to explain the importance of the set $\mathcal{T}$ from Equation \ref{eq:average_pricing_error}.
Initially, we introduced averaging over $\mathcal{T}$ to counter the ``exploding alpha" issue, first described by \cite{DLP12}, for cash flow streams with a very small initial cash flow.
The exploding alpha problem depicts the mathematical fact that in a net present value formula, a discount factor with a very large alpha term discounts all cash flows (after the first one) close to zero.
Thus, in this degenerate situation, the beta factors become irrelevant -- an infinite alpha almost perfectly prices the cash flow stream.
Even more importantly, our simulation study in Section \ref{sec:simulation_study} indicates that averaging over $\mathcal{T}$ seems to decrease the asymptotic bias of the estimator empirically.

A discounting date $\tau \in \mathcal{T}_{i}$ is a discretionary point in time where all fund cash flows are discounted to.
The cardinality $\mathrm{card}(\mathcal{T}_{i}) = \left| \mathcal{T}_{i} \right|$ gives the number of discounting dates used for the $i$th fund.
The smallest possible set $\mathcal{T}_i$ contains just the fund's starting date; in this case, $\mathrm{card}(\mathcal{T}_{i})$ consequently is one.
This corresponds to a typical NPV calculation in finance and is also used by \cite{DLP12} and \cite{KN16}.
In contrast, the largest candidate set for $\mathcal{T}$ contains all time periods bigger than the fund's starting date until now.
In Subsection \ref{sec:simulation_study}, we study the optimal set size of $\mathcal{T}$ by Monte Carlo simulations.
There we show in our example that controlling for the optimal size of $\mathcal{T}$ can control the asymptotic bias and variance of the original \cite{DLP12} estimator that just discounts all cash flows to the fund inception date.
As we average over $\mathcal{T}_i$ in Equation \ref{eq:average_pricing_error} we call $\bar{\epsilon}_{i}$ the $\mathcal{T}_i$-averaged pricing error, as visualized in Figure \ref{fig:npvs}.


\subsection{Cross-sectional unit: individual fund vs.\ portfolio of funds}
\label{sec:cross_sectional_unit}

According to the classical value-additivity assumption in \cite{HR87}, SDF models invariably shall hold for all pooled or unpooled assets.
As discussed in Subsection \ref{sec:asset_pricing_pooled}, it is best to use the underlying deals as test assets for SDF estimation to avoid the bias terms caused by pooled fund cash flows.
For the second best alternative, it is theoretically not important if the test assets for our SDF are portfolio or individual fund cash flows when the investment dates are the same.
Empirically it makes a difference, and there are arguments both for and against portfolio formation.

In the risk premium literature, portfolio formation mainly helps to attenuate the errors-in-variables bias connected to two-pass asset pricing methods \citep{JNPR19,PRS19}.
As this is no issue in our case, we could use individual funds.
\cite{C11} argues that portfolio sorting (seen as an auxiliary nonparametric regression that imposes linearity on the relationship between returns and characteristics) shall be replaced by multivariate panel models due to the curse of dimensionality.
Following the same nonparametric regression viewpoint, \cite{CCF19} derive a nonparametric framework where the optimal number of portfolio sorts acts as a data-dependent tuning parameter that grows with sample size.
Generally, the larger the portfolios, the easier any given SDF can price their cash flows since fewer test assets remain.

In the case of private equity funds, the pooling of fund cash flows helps to counter GP financial engineering\footnote{GPs may use bridge credit facilities below the hurdle rate to boost the fund's internal rate of return. This increases the probability of observing funds with only positive or only negative cash flows. However, we want to avoid (the possibility of) cross-sectional units that exhibit just cash flows with the same algebraic sign. Realistic SDFs never can price these cash flow streams.}, which might both change and mask the true risk profile of observed LP cash flows.
Especially for private equity funds, portfolio formation based on vintage years is compelling due to its time-series-like indexing as done by \cite{DLP12}.
This procedure also offers substantial computational benefits as it drastically decreases the number of cross-sectional units.
Further, as stated in \cite{ALS20}, portfolio formation allows more precise factor loading estimates due to decreasing idiosyncratic risk, but at the expense of sacrificing cross-sectional information.
Finally, small (or fixed) $T$ and large $N$ set-ups may face finite sample problems \citep{RRZ20}.
\begin{assume}
	\label{as:portfolio}
	For each vintage year, we pool fund cash flows to form $n_v$ portfolios that serve as cross-sectional units.
	Thus, $n = \sum_{v=1}^V n_v$.
	The two boundary cases are (i) single fund portfolios and (ii) just one portfolio per vintage year. 
\end{assume}
Without loss of generality, we refer to our cross-sectional units as funds, although this corresponds to a special case of our portfolio concept.
In the simulation study in Subsection \ref{sec:simulation_study}, we compare both boundary cases (i) individual funds and (ii) vintage year portfolios.

Thinking more broadly, we could even imagine more extreme boundary cases: 
(iii) on the one hand, we could pool \emph{all} fund cash flows to form only \emph{one} global moment condition for private equity similar to \cite{KN16} and accept potential under-identification; 
(iv) on the other hand, we could operate on underlying deal level like \cite{B14,B16a,B16b} and use gross-of-fee cash flows.





GMM estimators typically have a fixed number of moment conditions.
Thus, GMM estimators, where the number of moment conditions is allowed to grow with sample size, require special attention \citep{HP06,NW09}.
In many cases, it is probably most convenient to limit the maximum to a finite number of moment conditions (i.e., not each vintage year should form a moment condition).
In this paper, we employ nonlinear least squares estimators since they do not suffer from this ``number of moment condition" issue.




\subsubsection{Consistency}

The estimator $\hat{\theta}$ shall converge in probability to the true parameter value $\theta_0$ as the number of distinct vintage years in our data set goes to infinity.
Multiple funds for a specific vintage year are not necessarily required but provide additional information that we want to exploit if available.

\begin{lemma}
	\label{lem:consistency}
	A modified version of \citep[Theorem 2.1]{NM94} holds, i.e.,
	if there is a function $Q_0(\theta)$ such that 
	\begin{enumerate}
		\item Identification: $Q_0(\theta)$ is uniquely maximized at $\theta_0$,
		\item Boundedness: $\Theta$ is compact,
		\item Continuity: $Q_0(\theta)$ is continuous,
		\item Uniform convergence: $\hat{Q}_n(\theta)$ converges uniformly in probability to $Q_0(\theta)$,
	\end{enumerate}
	then $\hat{\theta} \xrightarrow{p} \theta_0$ as $n \rightarrow \infty$.
\end{lemma}

\begin{proof}
	The general proof is given in \cite[Chapter 2]{NM94} for a $\max$ instead of $\min$ extremum estimator.
	Thus, we only recapitulate the four conditions required by the lemma in our specific context.
	\begin{enumerate}
		\item 
		Then, we need to first show that $\mathbb{E} \left[ \bar{\epsilon} (\theta_0) \right] = x$, where $x$ is the minimum bias achievable, see Proposition \ref{theo:pooled_bias}.
		Secondly, we know $Q_0(\theta_0) = \mathbb{E} \left[ L \left( \bar{\epsilon} (\theta_0) \right) \right] \geq 0$, e.g., for $L(x)=x^2$ we have $Q_0(\theta) = \mathbb{E} \left[ \left( \bar{\epsilon} (\theta) \right)^2 \right] = \mathrm{Var} \left[ \bar{\epsilon} (\theta) \right] +  \left( \mathbb{E} \left[ \bar{\epsilon} (\theta) \right] \right)^2 $ where the second summand can be perceived as bias term that is zero for $\theta_0$.
		The variance term $\mathrm{Var} \left[ \bar{\epsilon} (\theta) \right]$ for a simplified DGP is analyzed by Corollary \ref{coro:epsilon_variance_bounds}.
		\item 
		Compactness of $\Theta$ can be assured by lower and upper bounds for all parameters that can be justified by economic reasoning. 
		In our case, e.g., a market beta factor of ten seems implausible for PE funds because of the implied risk and return expectations.
		\item 
		Continuity of the limit is a quiet weak and thus a standard regularity condition.
		\item 
		The second standard regularity condition is given by Assumption \ref{as:lln} which satisfies the definition of uniform convergence in probability \cite[Section 2.1]{NM94} . 
		To make this obvious, we can write $\hat{Q}_n(\theta) = Q_n(\theta) = n^{-1} \sum_{i=1}^n L \left( \bar{\epsilon}_i \right)$ and $Q_0(\theta) = \mathbb{E} \left[ Q_n(\theta) \right]$ and compare it to Assumption \ref{as:lln}.
	\end{enumerate}
	$\square$
\end{proof}


\subsubsection{Central limit theorem}

To assess the large-sample significance of our parameter estimates (as done in the following Subsection \ref{sec:asymptotic_inference}), we want to describe the asymptotic distribution of the parameter vector as a normal distribution.

\begin{proposition}
	\label{prop:clt}
	With estimator consistency established in Lemma \ref{lem:consistency}, and the five (technical) conditions from \cite[Theorem 3.1]{NM94} satisfied, it holds
	\begin{enumerate}
		\item $\sqrt{n}(\hat{\theta} - \theta_0) \overset{d}{\to} \mathcal{N}(0,{\Sigma})$ as $V,n \to \infty$ with covariance matrix ${\Sigma}$, and
		\item The covariance matrix ${\Sigma}$ can be characterized by \citet[Theorem 11.2.b, Theorem H.1]{PP97} (as outlined in the next Section \ref{sec:asymptotic_inference}).
	\end{enumerate}
\end{proposition}

\begin{proof}
	The extended proof of Proposition \ref{prop:clt} may be derived in analogy to the GMM case in \cite[Theorem 4]{JP12} that shows that the general structure of the \cite{PP97} framework also applies to the spatial near-epoch dependent case.
	Alternatively (and easier), the estimator from Equation \ref{eq:estimator} can be clearly formulated as extremum estimator in alignment with our Definition \ref{def:extremum_estimator}.
	In consequence, \cite[Theorem 3.1]{NM94}, which generally describes the asymptotic normality of extremum estimators, is directly applicable to obtain the stated result.
	Thus, all details of the proof can be found in the original reference \cite[Chapter 3]{NM94}.
	$\square$
\end{proof}


\subsection{Large sample inference}
\label{sec:asymptotic_inference}


In this subsection, we demonstrate how to empirically apply Proposition \ref{prop:clt} to obtain the asymptotic standard errors for our estimator from Equation \ref{eq:estimator}.


In the time-series, near-epoch-dependent LMD literature, the covariance matrix ${\Sigma}$ can be characterized according to \citet[Theorem 11.2.b, Theorem H.1]{PP97}:
\[
{\Sigma} = H^{-1} \Lambda (H^{-1})^\top
\]
with expected Hessian matrix converging to $H$ as $n \to \infty$
\[
\mathbb{E}
\left[
\nabla_{\theta \theta} Q_n
\right]
\overset{p}{\to}
H
\]
and the expected covariance matrix of gradients converging to $\Lambda$ as $n \to \infty$
\[
n \cdot \mathbb{E}
\left[
\nabla_{\theta} Q_n
(\nabla_{\theta} Q_n)^\top
\right]
\overset{p}{\to}
\Lambda
\]
Here, the gradient vector $\nabla_{\theta} Q_n$ is denoted as column vector.



\subsection{Comparison to similar estimators}



\begin{table}[ht]
	\centering
	\resizebox{0.9\textwidth}{!}{%
		\begin{tabular}{llll}
			& \cite{DLP12} & \cite{KN16} & Our approach \\ 
			\hline
			\hline
			M-estimator & Cross-sectional Generalized & Time-series Generalized  & Least-Mean-  \\
			& Method of Moments & Method of Moments & Distance \\
			\hline
			Pricing error averaging & No & No & Yes \\
			\hline
			Cash flows priced & PE cash flows & public cash flows & PE cash flows \\
			\hline
			Asymptotics & cross-sectional & time-series & spatial \\
			& \#funds $\to \infty$ & \#vintages $\to \infty$ & \# of both $\to \infty$ \\
			\hline
			Inference & bootstrap & spatial HAC & cross-validation \\
			& & & \& spatial HAC \\
			\hline
			Cross-sectional unit & vintage year portfolio & single fund & testing both \\
			\hline
			SDF & simple linear & exponentially affine & testing both \\
			\hline
			\hline
		\end{tabular}
	}
	\caption{Comparison to similar estimation frameworks.} 
	\label{tab:comparison}
\end{table}
